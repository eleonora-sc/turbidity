{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kachemak Bay Turbidity - Exploratory Data Analysis \n",
    "This notebook: <br>\n",
    "1. Pulls the most recent data from ERDDAP for Seldovia and Homer Surface and Deep Water.\n",
    "2. Performs Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the most recent data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV file for sensor 1 saved successfully as 'seldovia_swq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 2 saved successfully as 'seldovia_dwq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 3 saved successfully as 'homer_dwq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 4 saved successfully as 'homer_swq.csv' in the /data directory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage where the CSV link is located\n",
    "data_dict = {'seldovia_swq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kacsswq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'seldovia_dwq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kacsdwq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'homer_dwq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kachdwq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'homer_swq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kach3wq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            }\n",
    "\n",
    "print()\n",
    "# Send a GET request to the URL\n",
    "for i, sensor in enumerate(list(data_dict)):\n",
    "    response = requests.get(list(data_dict.values())[i])\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Get the content of the response (CSV data)\n",
    "        csv_data = response.content\n",
    "        \n",
    "        # Specify the file name for saving the CSV\n",
    "        csv_file_name = list(data_dict.keys())[i]\n",
    "        \n",
    "        # Write the CSV data to a file in the current directory\n",
    "        with open('data/'+csv_file_name, 'wb') as csv_file:\n",
    "            csv_file.write(csv_data)\n",
    "        \n",
    "        print(f\"CSV file for sensor {i+1} saved successfully as '{csv_file_name}' in the /data directory.\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to download CSV file for sensor {i+1}. Status code: {response.status_code}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['homer_dwq.csv', 'homer_swq.csv', 'seldovia_dwq.csv', 'seldovia_swq.csv']\n"
     ]
    }
   ],
   "source": [
    "# List all csv files in the data directory \n",
    "csv_files = [f for f in os.listdir('data') if f.endswith('.csv')]\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Measurement Date for homer_dwq.csv: 2003-01-01 09:00:00\n",
      "Last Measurement Date for homer_dwq.csv: 2024-10-08 15:15:00\n",
      "Average Measurement Interval for homer_dwq.csv: 0 hours, 15 minutes\n",
      "\n",
      "\n",
      "First Measurement Date for homer_swq.csv: 2012-05-31 21:15:00\n",
      "Last Measurement Date for homer_swq.csv: 2024-10-01 18:00:00\n",
      "Average Measurement Interval for homer_swq.csv: 0 hours, 18 minutes\n",
      "\n",
      "\n",
      "First Measurement Date for seldovia_dwq.csv: 2004-01-01 09:00:00\n",
      "Last Measurement Date for seldovia_dwq.csv: 2024-10-02 17:30:00\n",
      "Average Measurement Interval for seldovia_dwq.csv: 0 hours, 15 minutes\n",
      "\n",
      "\n",
      "First Measurement Date for seldovia_swq.csv: 2004-01-01 09:00:00\n",
      "Last Measurement Date for seldovia_swq.csv: 2024-10-02 17:45:00\n",
      "Average Measurement Interval for seldovia_swq.csv: 0 hours, 15 minutes\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_resolution():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "        # Convert the time column entries into a datetime type\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "        # Calculate the average measurement interval\n",
    "        avg_interval = df['time'].diff().mean()\n",
    "\n",
    "        # Get the first and last measurement dates\n",
    "        first_measurement_date = df['time'].min()\n",
    "        last_measurement_date = df['time'].max()\n",
    "\n",
    "        # Display the results\n",
    "        print(f\"First Measurement Date for {csv}:\", first_measurement_date.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(f\"Last Measurement Date for {csv}:\", last_measurement_date.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(f\"Average Measurement Interval for {csv}: {avg_interval.components.hours} hours, {avg_interval.components.minutes} minutes\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "data_resolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Quality of homer_dwq.csv:\n",
      "Total entries: 724689\n",
      "Percentage of PASS entries: 74.8%\n",
      "Percentage of NOT_EVALUATED entries: 16.4%\n",
      "Percentage of SUSPECT entries: 4.7%\n",
      "Percentage of FAIL entries: 4.1%\n",
      "Percentage of MISSING entries: 0.0%\n",
      "Pass/Fail rate: 18.5\n",
      "------------------------------------------------------------\n",
      "Quality of homer_swq.csv:\n",
      "Total entries: 343585\n",
      "Percentage of PASS entries: 89.4%\n",
      "Percentage of NOT_EVALUATED entries: 0.0%\n",
      "Percentage of SUSPECT entries: 3.3%\n",
      "Percentage of FAIL entries: 7.3%\n",
      "Percentage of MISSING entries: 0.0%\n",
      "Pass/Fail rate: 12.2\n",
      "------------------------------------------------------------\n",
      "Quality of seldovia_dwq.csv:\n",
      "Total entries: 712744\n",
      "Percentage of PASS entries: 73.3%\n",
      "Percentage of NOT_EVALUATED entries: 14.4%\n",
      "Percentage of SUSPECT entries: 9.5%\n",
      "Percentage of FAIL entries: 2.8%\n",
      "Percentage of MISSING entries: 0.0%\n",
      "Pass/Fail rate: 26.6\n",
      "------------------------------------------------------------\n",
      "Quality of seldovia_swq.csv:\n",
      "Total entries: 709687\n",
      "Percentage of PASS entries: 74.1%\n",
      "Percentage of NOT_EVALUATED entries: 14.1%\n",
      "Percentage of SUSPECT entries: 6.5%\n",
      "Percentage of FAIL entries: 5.4%\n",
      "Percentage of MISSING entries: 0.0%\n",
      "Pass/Fail rate: 13.6\n"
     ]
    }
   ],
   "source": [
    "def data_quality():\n",
    "    # From https://erddap.aoos.org/erddap/tabledap/nerrs_kacsswq.html\n",
    "    qc_flag_meanings =  {\n",
    "                        'PASS'          : 1,\n",
    "                        'NOT_EVALUATED' : 2,\n",
    "                        'SUSPECT'       : 3,\n",
    "                        'FAIL'          : 4,\n",
    "                        'MISSING'       : 9\n",
    "                        }\n",
    "\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity_qc_agg' column a type int instead of float\n",
    "        df['sea_water_turbidity_qc_agg'] = df['sea_water_turbidity_qc_agg'].astype(int)\n",
    "\n",
    "        # Count the occurrences of each value in the 'sea_water_turbidity_qc_agg' column\n",
    "        counts = df['sea_water_turbidity_qc_agg'].value_counts()\n",
    "        \n",
    "        # Get the total number of rows\n",
    "        total_rows = df.shape[0]\n",
    "\n",
    "        # # Print the counts (UNCOMMENT FOR TESTING)\n",
    "        # print(counts)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "        # counts.get(X, y) gets the value in the counts series for X and defaults to value y if X is not found\n",
    "        if counts.get(4, 0) > 0: \n",
    "            pass_fail_rate = counts.get(1, 0) / counts.get(4, 0) \n",
    "        else:\n",
    "            pass_fail_rate = float('inf')  # To handle the case where there are no fail entries\n",
    "\n",
    "        print(f\"Quality of {csv}:\")\n",
    "        print(f\"Total entries: {total_rows}\")\n",
    "        print(f\"Percentage of PASS entries: {(counts.get(1, 0) / total_rows * 100):.1f}%\") \n",
    "        print(f\"Percentage of NOT_EVALUATED entries: {(counts.get(2, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of SUSPECT entries: {(counts.get(3, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of FAIL entries: {(counts.get(4, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of MISSING entries: {(counts.get(9, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Pass/Fail rate: {pass_fail_rate:.1f}\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "data_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of homer_dwq.csv:\n",
      "Lowest Value: 0.00\n",
      "Highest Value: 1923.00\n",
      "Mean: 3.03\n",
      "Median: 2.00\n",
      "Mode: 2.00\n",
      "25th Percentile: 1.00\n",
      "50th Percentile (Median): 2.00\n",
      "75th Percentile: 3.00\n",
      "Range: 1923.00\n",
      "Variance: 66.50\n",
      "Standard Deviation: 8.15\n",
      "\n",
      "\n",
      "Quality of homer_swq.csv:\n",
      "Lowest Value: 0.00\n",
      "Highest Value: 286.00\n",
      "Mean: 4.29\n",
      "Median: 2.00\n",
      "Mode: 2.00\n",
      "25th Percentile: 2.00\n",
      "50th Percentile (Median): 2.00\n",
      "75th Percentile: 4.00\n",
      "Range: 286.00\n",
      "Variance: 51.11\n",
      "Standard Deviation: 7.15\n",
      "\n",
      "\n",
      "Quality of seldovia_dwq.csv:\n",
      "Lowest Value: 0.00\n",
      "Highest Value: 568.00\n",
      "Mean: 1.28\n",
      "Median: 1.00\n",
      "Mode: 1.00\n",
      "25th Percentile: 0.00\n",
      "50th Percentile (Median): 1.00\n",
      "75th Percentile: 1.00\n",
      "Range: 568.00\n",
      "Variance: 24.88\n",
      "Standard Deviation: 4.99\n",
      "\n",
      "\n",
      "Quality of seldovia_swq.csv:\n",
      "Lowest Value: 0.00\n",
      "Highest Value: 204.00\n",
      "Mean: 1.19\n",
      "Median: 1.00\n",
      "Mode: 1.00\n",
      "25th Percentile: 0.00\n",
      "50th Percentile (Median): 1.00\n",
      "75th Percentile: 1.00\n",
      "Range: 204.00\n",
      "Variance: 8.51\n",
      "Standard Deviation: 2.92\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def statistical_metrics():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 (PASS)\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "    \n",
    "        # Calculate statistics\n",
    "        min_value = df_filtered['sea_water_turbidity'].min()\n",
    "        max_value = df_filtered['sea_water_turbidity'].max()\n",
    "        mean = df_filtered['sea_water_turbidity'].mean()\n",
    "        median = df_filtered['sea_water_turbidity'].median()\n",
    "        mode = df_filtered['sea_water_turbidity'].mode()[0]  # mode() returns a Series\n",
    "        percentiles = df_filtered['sea_water_turbidity'].quantile([0.25, 0.5, 0.75])\n",
    "        range_ = df_filtered['sea_water_turbidity'].max() - df_filtered['sea_water_turbidity'].min()\n",
    "        variance = df_filtered['sea_water_turbidity'].var()\n",
    "        std_dev = df_filtered['sea_water_turbidity'].std()\n",
    "        \n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Quality of {csv}:\")\n",
    "        print(f\"Lowest Value: {min_value:.2f}\")\n",
    "        print(f\"Highest Value: {max_value:.2f}\")\n",
    "        print(f\"Mean: {mean:.2f}\")\n",
    "        print(f\"Median: {median:.2f}\")\n",
    "        print(f\"Mode: {mode:.2f}\")\n",
    "        print(f\"25th Percentile: {percentiles[0.25]:.2f}\")\n",
    "        print(f\"50th Percentile (Median): {percentiles[0.5]:.2f}\")\n",
    "        print(f\"75th Percentile: {percentiles[0.75]:.2f}\")\n",
    "        print(f\"Range: {range_:.2f}\")\n",
    "        print(f\"Variance: {variance:.2f}\")\n",
    "        print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "statistical_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line Graphs of Turbidity vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_turbidity_vs_time_individual():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 ('PASS')\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "\n",
    "        # Ensure 'time' is in datetime format\n",
    "        df_filtered.loc[:, 'time'] = pd.to_datetime(df_filtered['time'])\n",
    "\n",
    "        # # Plot turbidity over time\n",
    "        # plt.figure(figsize=(12, 6))\n",
    "        # plt.plot(df_filtered['time'], df_filtered['sea_water_turbidity'], linestyle='-', color='b')\n",
    "        # plt.xlabel('Time')\n",
    "        # plt.ylabel('Sea Water Turbidity (NTU)')\n",
    "        # plt.title(f'Sea Water Turbidity Over Time for {csv}')\n",
    "        # plt.grid(True)\n",
    "        # plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "        # plt.tight_layout()  # Adjust layout to fit labels\n",
    "        # plt.show()\n",
    "\n",
    "        # Create Plotly figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add the turbidity vs. time line plot\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_filtered['time'],\n",
    "            y=df_filtered['sea_water_turbidity'],\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            name=f'Turbidity for {csv}'\n",
    "        ))\n",
    "\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            title=f'Sea Water Turbidity Over Time for {csv}',\n",
    "            xaxis_title='Time',\n",
    "            yaxis_title='Sea Water Turbidity (NTU)',\n",
    "            xaxis=dict(tickformat='%Y-%m-%d', tickangle=45),  # Format x-axis for better readability\n",
    "            template='plotly_white',\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "# Run the function\n",
    "plot_turbidity_vs_time_individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_turbidity_vs_time_combined():\n",
    "\n",
    "    # Create plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 ('PASS')\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "\n",
    "        # Ensure 'time' is in datetime format\n",
    "        df_filtered.loc[:, 'time'] = pd.to_datetime(df_filtered['time'])\n",
    "\n",
    "        # Add the turbidity vs. time line plot\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_filtered['time'],\n",
    "            y=df_filtered['sea_water_turbidity'],\n",
    "            mode='lines',\n",
    "            line=dict(),\n",
    "            name=f'Turbidity for {csv}'\n",
    "        ))\n",
    "    \n",
    "        # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'Sea Water Turbidity Over Time',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Sea Water Turbidity (NTU)',\n",
    "        xaxis=dict(tickformat='%Y-%m-%d', tickangle=45),  # Format x-axis for better readability\n",
    "        template='seaborn   ',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Run the function\n",
    "plot_turbidity_vs_time_combined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly Binned Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eleonora\\AppData\\Local\\Temp\\ipykernel_22008\\1905459569.py:21: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_monthly_boxplot():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 ('PASS')\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "\n",
    "        # Ensure 'time' is in datetime format\n",
    "        df_filtered.loc[ : , 'time'] = pd.to_datetime(df_filtered['time'], errors='raise') # This will make the column of type pandas timestamp\n",
    "        assert all(isinstance(x, pd.Timestamp) for x in df_filtered['time']), \"Not all values in 'time' are Timestamps\"        \n",
    "\n",
    "        # Extract the month (only) for grouping\n",
    "        df_filtered.loc[ : , 'month'] = df_filtered['time'].apply(lambda x: x.strftime('%B'))\n",
    "        # print(df_filtered['time'].iloc[1].strftime('%B'))\n",
    "\n",
    "        fig = px.box(df_filtered, \n",
    "                    x='month', \n",
    "                    y='sea_water_turbidity', \n",
    "                    title='Sea Water Turbidity Distribution by Month',\n",
    "                    category_orders={'month': ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                                                'July', 'August', 'September', 'October', 'November', 'December']},\n",
    "                    labels={'month': 'Month', 'sea_water_turbidity': 'Sea Water Turbidity (NTU)'})\n",
    "\n",
    "        fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "        \n",
    "        break\n",
    "        \n",
    "create_monthly_boxplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
