{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kachemak Bay Turbidity - Exploratory Data Analysis \n",
    "This script: <br>\n",
    "1. Pulls the most recent data from ERDDAP for Seldovia and Homer Surface and Deep Water.\n",
    "2. Performs Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the most recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV file for sensor 1 saved successfully as 'seldovia_swq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 2 saved successfully as 'seldovia_dwq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 3 saved successfully as 'homer_dwq.csv' in the /data directory.\n",
      "\n",
      "CSV file for sensor 4 saved successfully as 'homer_swq.csv' in the /data directory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage where the CSV link is located\n",
    "data_dict = {'seldovia_swq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kacsswq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'seldovia_dwq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kacsdwq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'homer_dwq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kachdwq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            'homer_swq.csv' : 'https://erddap.aoos.org/erddap/tabledap/nerrs_kach3wq.csv?time%2Csea_water_turbidity%2Csea_water_turbidity_qc_agg',\n",
    "            }\n",
    "\n",
    "print()\n",
    "# Send a GET request to the URL\n",
    "for i, sensor in enumerate(list(data_dict)):\n",
    "    response = requests.get(list(data_dict.values())[i])\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Get the content of the response (CSV data)\n",
    "        csv_data = response.content\n",
    "        \n",
    "        # Specify the file name for saving the CSV\n",
    "        csv_file_name = list(data_dict.keys())[i]\n",
    "        \n",
    "        # Write the CSV data to a file in the current directory\n",
    "        with open('data/'+csv_file_name, 'wb') as csv_file:\n",
    "            csv_file.write(csv_data)\n",
    "        \n",
    "        print(f\"CSV file for sensor {i+1} saved successfully as '{csv_file_name}' in the /data directory.\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to download CSV file for sensor {i+1}. Status code: {response.status_code}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all csv files in the data directory \n",
    "csv_files = [f for f in os.listdir('data') if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_resolution():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "        # Convert the time column entries into a datetime type\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "        # Calculate the average measurement interval\n",
    "        avg_interval = df['time'].diff().mean()\n",
    "\n",
    "        # Get the first and last measurement dates\n",
    "        first_measurement_date = df['time'].min()\n",
    "        last_measurement_date = df['time'].max()\n",
    "\n",
    "        # Display the results\n",
    "        print(f\"First Measurement Date for {csv}:\", first_measurement_date.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(f\"Last Measurement Date for {csv}:\", last_measurement_date.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(f\"Average Measurement Interval for {csv}: {avg_interval.components.hours} hours, {avg_interval.components.minutes} minutes\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "data_resolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality():\n",
    "    # From https://erddap.aoos.org/erddap/tabledap/nerrs_kacsswq.html\n",
    "    qc_flag_meanings =  {\n",
    "                        'PASS'          : 1,\n",
    "                        'NOT_EVALUATED' : 2,\n",
    "                        'SUSPECT'       : 3,\n",
    "                        'FAIL'          : 4,\n",
    "                        'MISSING'       : 9\n",
    "                        }\n",
    "\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity_qc_agg' column a type int instead of float\n",
    "        df['sea_water_turbidity_qc_agg'] = df['sea_water_turbidity_qc_agg'].astype(int)\n",
    "\n",
    "        # Count the occurrences of each value in the 'sea_water_turbidity_qc_agg' column\n",
    "        counts = df['sea_water_turbidity_qc_agg'].value_counts()\n",
    "        \n",
    "        # Get the total number of rows\n",
    "        total_rows = df.shape[0]\n",
    "\n",
    "        # # Print the counts (UNCOMMENT FOR TESTING)\n",
    "        # print(counts)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "        # counts.get(X, y) gets the value in the counts series for X and defaults to value y if X is not found\n",
    "        if counts.get(4, 0) > 0: \n",
    "            pass_fail_rate = counts.get(1, 0) / counts.get(4, 0) \n",
    "        else:\n",
    "            pass_fail_rate = float('inf')  # To handle the case where there are no fail entries\n",
    "\n",
    "        print(f\"Quality of {csv}:\")\n",
    "        print(f\"Total entries: {total_rows}\")\n",
    "        print(f\"Percentage of PASS entries: {(counts.get(1, 0) / total_rows * 100):.1f}%\") \n",
    "        print(f\"Percentage of NOT_EVALUATED entries: {(counts.get(2, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of SUSPECT entries: {(counts.get(3, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of FAIL entries: {(counts.get(4, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Percentage of MISSING entries: {(counts.get(9, 0) / total_rows * 100):.1f}%\")\n",
    "        print(f\"Pass/Fail rate: {pass_fail_rate:.1f}\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "data_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_metrics():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 (PASS)\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "    \n",
    "        # Calculate statistics\n",
    "        min_value = df_filtered['sea_water_turbidity'].min()\n",
    "        max_value = df_filtered['sea_water_turbidity'].max()\n",
    "        mean = df_filtered['sea_water_turbidity'].mean()\n",
    "        median = df_filtered['sea_water_turbidity'].median()\n",
    "        mode = df_filtered['sea_water_turbidity'].mode()[0]  # mode() returns a Series\n",
    "        percentiles = df_filtered['sea_water_turbidity'].quantile([0.25, 0.5, 0.75])\n",
    "        range_ = df_filtered['sea_water_turbidity'].max() - df_filtered['sea_water_turbidity'].min()\n",
    "        variance = df_filtered['sea_water_turbidity'].var()\n",
    "        std_dev = df_filtered['sea_water_turbidity'].std()\n",
    "        \n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Quality of {csv}:\")\n",
    "        print(f\"Lowest Value: {min_value:.2f}\")\n",
    "        print(f\"Highest Value: {max_value:.2f}\")\n",
    "        print(f\"Mean: {mean:.2f}\")\n",
    "        print(f\"Median: {median:.2f}\")\n",
    "        print(f\"Mode: {mode:.2f}\")\n",
    "        print(f\"25th Percentile: {percentiles[0.25]:.2f}\")\n",
    "        print(f\"50th Percentile (Median): {percentiles[0.5]:.2f}\")\n",
    "        print(f\"75th Percentile: {percentiles[0.75]:.2f}\")\n",
    "        print(f\"Range: {range_:.2f}\")\n",
    "        print(f\"Variance: {variance:.2f}\")\n",
    "        print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "statistical_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_turbidity_vs_time():\n",
    "    for csv in csv_files:\n",
    "        # Load csv file into a DataFrame\n",
    "        df = pd.read_csv(f\"data/{csv}\", low_memory=False)\n",
    "\n",
    "        # # Display the first few rows to verify (UNCOMMENT FOR TESTING)\n",
    "        # print(df.head())\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # Remove the first row containing units and reindex\n",
    "        df = df.drop(index=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Make the 'sea_water_turbidity' column a type int instead of float\n",
    "        df['sea_water_turbidity'] = df['sea_water_turbidity'].astype(float)\n",
    "\n",
    "        # Only include rows where 'sea_water_turbidity_qc_agg' is 1 ('PASS')\n",
    "        df_filtered = df[df['sea_water_turbidity_qc_agg'].astype(int) == 1]\n",
    "\n",
    "        # Ensure 'time' is in datetime format\n",
    "        df_filtered.loc[:, 'time'] = pd.to_datetime(df_filtered['time'])\n",
    "\n",
    "        # Plot turbidity over time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df_filtered['time'], df_filtered['sea_water_turbidity'], linestyle='-', color='b')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Sea Water Turbidity (NTU)')\n",
    "        plt.title(f'Sea Water Turbidity Over Time for {csv}')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "        plt.tight_layout()  # Adjust layout to fit labels\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Run the function\n",
    "plot_turbidity_vs_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
